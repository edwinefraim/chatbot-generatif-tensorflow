{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "human_data = pd.read_table(\"data/human_text_indo.txt\", header=None)\n",
    "human_data.columns=[\"human\"]\n",
    "robot_data = pd.read_table(\"data/robot_text_indo.txt\", header=None)\n",
    "robot_data.columns=[\"robot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>robot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[mulai]</td>\n",
       "      <td>Hai apa kabar ! ? 游때游때</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oh terima kasih ! saya baik-baik saja. ini ada...</td>\n",
       "      <td>ini sudah sore!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bagaimana perasaanmu hari ini ? ceritakan kepa...</td>\n",
       "      <td>nama saya rdany, tetapi Anda bisa memanggil sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>berapa banyak teman virtual yang kamu punya?</td>\n",
       "      <td>saya punya banyak ! tetapi tidak cukup untuk s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>apakah itu dilarang bagi Anda untuk memberi ta...</td>\n",
       "      <td>saya telah berbicara dengan 143 pengguna, meng...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               human  \\\n",
       "0                                            [mulai]   \n",
       "1  Oh terima kasih ! saya baik-baik saja. ini ada...   \n",
       "2  bagaimana perasaanmu hari ini ? ceritakan kepa...   \n",
       "3       berapa banyak teman virtual yang kamu punya?   \n",
       "4  apakah itu dilarang bagi Anda untuk memberi ta...   \n",
       "\n",
       "                                               robot  \n",
       "0                               Hai apa kabar ! ? 游때游때  \n",
       "1                                    ini sudah sore!  \n",
       "2  nama saya rdany, tetapi Anda bisa memanggil sa...  \n",
       "3  saya punya banyak ! tetapi tidak cukup untuk s...  \n",
       "4  saya telah berbicara dengan 143 pengguna, meng...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = {'human':human_data.human, 'robot':robot_data.robot}\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengganti kata didalam kurung siku [...] menjadi kata hai\n",
    "import re\n",
    "df.human = df.human.apply(lambda x : re.sub(r\"\\[w+\\]\",\"hai\", x))\n",
    "df.robot = df.robot.apply(lambda x : re.sub(r\"\\[w+\\]\",\"hai\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#koversi ke huruf kecil (Casefolding)\n",
    "df.human = df.human.apply(lambda x: x.lower())\n",
    "df.robot = df.robot.apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hapus tanda baca (stopword removal)\n",
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "df.human = df.human.apply(lambda x : ''.join(ch for ch in x if ch not in exclude))\n",
    "df.robot = df.robot.apply(lambda x : ''.join(ch for ch in x if ch not in exclude))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hapus angka\n",
    "remove_digits = str.maketrans('','',string.digits)\n",
    "df.human = df.human.apply(lambda x: x.translate(remove_digits))\n",
    "df.robot = df.robot.apply(lambda x: x.translate(remove_digits))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hapus emoticon\n",
    "df.human = df.human.apply(lambda x: x.encode('ascii','ignore').decode('ascii'))\n",
    "df.robot = df.robot.apply(lambda x: x.encode('ascii','ignore').decode('ascii'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(df, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2126, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(237, 2)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran Vocab : 3481\n"
     ]
    }
   ],
   "source": [
    "#buat vocab dari data training\n",
    "vocabulary = set ()\n",
    "for idx, row in df_train.iterrows():\n",
    "    sent = row.human + ' '+row.robot\n",
    "    [vocabulary.update(sent.split())]\n",
    "\n",
    "\n",
    "print(f\"Ukuran Vocab : {len(vocabulary)}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah Semua Token : 32557\n"
     ]
    }
   ],
   "source": [
    "all_vocab = []\n",
    "\n",
    "for idx, row in df_train.iterrows():\n",
    "    sent = row.human + ' ' +row.robot\n",
    "    [all_vocab.append(i) for i in sent.split()]\n",
    "\n",
    "print(f\"Jumlah Semua Token : {len(all_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "937"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hitung frekuensi vocab dan hapus yang tidak perlu (sedikit)\n",
    "from collections import Counter\n",
    "\n",
    "counter = Counter(all_vocab)\n",
    "\n",
    "dic_ = dict(counter)\n",
    "threshold = 3\n",
    "\n",
    "sorted_dic = sorted(dic_.items(), reverse=True, key=lambda x: x[1])\n",
    "sorted_dic = [x for x in sorted_dic if x[1] > threshold]\n",
    "all_vocab = [x[0] for x in sorted_dic]\n",
    "len(all_vocab) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buat dictionary word to idx & idx to word\n",
    "ix = 1 \n",
    "word_to_idx = {}\n",
    "idx_to_word = {}\n",
    "\n",
    "for e in all_vocab:\n",
    "    word_to_idx[e] = ix\n",
    "    idx_to_word[ix] = e\n",
    "    ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tambahkan \"startseq\" dan \"endseq\"\n",
    "word_to_idx['startseq'] = 938\n",
    "word_to_idx['endseq'] = 939\n",
    "\n",
    "idx_to_word[938] = 'startseq'\n",
    "idx_to_word[939] = 'endseq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(idx_to_word) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>robot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>hmm karena kamu selalu membaca pijatanku tapi ...</td>\n",
       "      <td>startseq saya mengerti sekarang  saya bot dan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>saya berharap begitu  saya akan merekomendasik...</td>\n",
       "      <td>startseq terima kasih  saya akan lihat  endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>dapatkah anda membantu saya menulis program di...</td>\n",
       "      <td>startseq tentu  apa yang ingin kamu lakukan  e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>oke apakah anda tahu beberapa permainan</td>\n",
       "      <td>startseq saya tahu tetris  bercanda endseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2358</th>\n",
       "      <td>mulai  f</td>\n",
       "      <td>startseq hai disini  apa kabarmu  endseq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  human  \\\n",
       "1703  hmm karena kamu selalu membaca pijatanku tapi ...   \n",
       "272   saya berharap begitu  saya akan merekomendasik...   \n",
       "1171  dapatkah anda membantu saya menulis program di...   \n",
       "691             oke apakah anda tahu beberapa permainan   \n",
       "2358                                           mulai  f   \n",
       "\n",
       "                                                  robot  \n",
       "1703  startseq saya mengerti sekarang  saya bot dan ...  \n",
       "272      startseq terima kasih  saya akan lihat  endseq  \n",
       "1171  startseq tentu  apa yang ingin kamu lakukan  e...  \n",
       "691          startseq saya tahu tetris  bercanda endseq  \n",
       "2358           startseq hai disini  apa kabarmu  endseq  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tambahkan \"startseq\" dan \"endseq\" di data train dibagian data robot\n",
    "df_train.robot = df.robot.apply(lambda x: 'startseq '+ x + ' endseq')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#buat data generator x1 = input, x2=output, y=output Neural Network\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "def data_generator(train_df,word_to_idx,max_len,number_conversation):\n",
    "    X1, X2, y = [],[],[]\n",
    "    n = 0\n",
    "    while True:\n",
    "        for idx, row in train_df.iterrows():\n",
    "            seq_human = [word_to_idx[word] for word in row ['human'].split() if word in word_to_idx]\n",
    "            seq_human = pad_sequences([seq_human], maxlen=max_len, value=0, padding='post') [0]\n",
    "            seq_robot = [word_to_idx[word] for word in row['robot'].split() if word in word_to_idx]\n",
    "\n",
    "            for i in range(1, len(seq_robot)):\n",
    "                in_seq = seq_robot[:i]\n",
    "                out_seq = seq_robot[i]\n",
    "\n",
    "                in_seq = pad_sequences([in_seq], maxlen=max_len, value=0, padding='post') [0]\n",
    "                out_seq = to_categorical ([out_seq],num_classes=vocab_size)[0]\n",
    "\n",
    "                X1.append(seq_human)\n",
    "                X2.append(in_seq)\n",
    "                y.append(out_seq)\n",
    "\n",
    "            if n==number_conversation:\n",
    "                #output [X1, X2, y]; yield lebih memori friendly dari array\n",
    "                yield([np.array(X1),np.array(X2),np.array(y)])\n",
    "                X1, X2, y = [], [], []\n",
    "                n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasample = df_train.sample(2)\n",
    "datagen = data_generator(datasample, word_to_idx, 50, len(datasample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>human</th>\n",
       "      <th>robot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625</th>\n",
       "      <td>baik  diberikan</td>\n",
       "      <td>startseq saya pikir kita bisa menjadi teman vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1733</th>\n",
       "      <td>ya kamu harus</td>\n",
       "      <td>startseq  endseq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                human                                              robot\n",
       "625   baik  diberikan  startseq saya pikir kita bisa menjadi teman vi...\n",
       "1733  ya kamu harus                                     startseq  endseq"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Embedding, LSTM, Add\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "max_len = 50\n",
    "input_chat = Input(shape=(max_len))\n",
    "input_x = Embedding(input_dim=vocab_size, output_dim=50, mask_zero=True)(input_chat)\n",
    "#mencegah overfit\n",
    "input_x = Dropout(0.3)(input_x)\n",
    "input_x = LSTM(256)(input_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_chat = Input(shape=(max_len))\n",
    "output_x = Embedding(input_dim=vocab_size, output_dim=50, mask_zero=True)(input_chat)\n",
    "#mencegah overfit\n",
    "output_x = Dropout(0.3)(output_x)\n",
    "output_x = LSTM(256)(output_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#penyatuan model\n",
    "decoder = Add()([input_x, output_x])\n",
    "decoder = Dense(256, activation='relu')(decoder)\n",
    "outputs = Dense(vocab_size, activation='softmax')(decoder)\n",
    "\n",
    "model = Model(inputs=[input_chat, output_chat], outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 50, 50)       47000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 50, 50)       47000       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 50, 50)       0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 50, 50)       0           ['embedding_1[0][0]']            \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    (None, 256)          314368      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  (None, 256)          314368      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 256)          0           ['lstm[0][0]',                   \n",
      "                                                                  'lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          65792       ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 50)]         0           []                               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 940)          241580      ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,030,108\n",
      "Trainable params: 1,030,108\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    " model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#konfigurasi training\n",
    "#melakukan training per25 conversation dalam 1 data set\n",
    "epochs = 10\n",
    "number_conversation = 25\n",
    "steps = len(df_train) // number_conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_train = data_generator(df_train, word_to_idx, max_len, number_conversation)\n",
    "model.fit(generator_train, epochs=3, steps_per_epoch=steps, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5eb0b7b3903eb5a3ee4d1a856f61893be0d579f0b8441396760ca22941a857cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
